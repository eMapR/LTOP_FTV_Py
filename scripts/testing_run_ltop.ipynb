{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is intended to run the full LandTrendr Optimization (LTOP) workflow implemented in Python. This tool is intended to be used to select the 'optiumum' version of the LandTrendr change detection algorithm (Kennedy et al., 2010, 2018) for different areas on a landscape. \n",
    "\n",
    "#### Notes\n",
    "- You need to authenticate the run with a specific GEE account. In the import params statement its going to trigger the ee.Authenticate() protocal which will prompt you to a browser page to authenticate using your GEE account. \n",
    "- Subsequent scripts have just the ee.Initialize protocal because you should have already authenicated and this should only happen once. \n",
    "- Right now this is going to import the params from a separate .py file and treat those as imports. It may actually be easier/more straight forward if we're going to stick with a Jupyter Notebook to just put these directly into a cell here in the Jupyter Notebook. \n",
    "- If you import a module at the top and then change something in the exe script you will need to restart or otherwise delete variables because that change won't be reflected otherwise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee \n",
    "import importlib\n",
    "import pandas as pd \n",
    "import ltop\n",
    "importlib.reload(ltop)\n",
    "import lt_params\n",
    "importlib.reload(lt_params)\n",
    "import run_SNIC_01 as runSNIC\n",
    "importlib.reload(runSNIC)\n",
    "import run_kMeans_02_1 as kmeans_1\n",
    "import run_kMeans_02_2 as kmeans_2\n",
    "import abstract_sampling_03 as ab_img\n",
    "import abstract_imager_04 as run_lt_pts\n",
    "importlib.reload(run_lt_pts)\n",
    "import ltop_lt_paramater_scoring_01 as param_scoring\n",
    "importlib.reload(param_scoring)\n",
    "import generate_LTOP_05 as make_bps\n",
    "importlib.reload(make_bps)\n",
    "import run_ltop_complete as runner\n",
    "from run_ltop_complete import RunLTOPFull,parse_params\n",
    "import yaml \n",
    "importlib.reload(runner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define an aoi \n",
    "aoi = ee.FeatureCollection(\"USDOS/LSIB/2017\").filter(ee.Filter.eq('COUNTRY_NA','Cambodia')).geometry()\n",
    "    # # aoi = ee.Geometry.Polygon(\n",
    "    # #     [[[105.21924736250195, 14.414700359899358],\n",
    "    # #       [105.21924736250195, 12.212492266993609],\n",
    "    # #       [107.62525322187695, 12.212492266993609],\n",
    "    # #       [107.62525322187695, 14.414700359899358]]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yml\", \"r\") as ymlfile:\n",
    "        cfg = yaml.safe_load(ymlfile)\n",
    "        cfg = parse_params(aoi,cfg) \n",
    "        # single_example = RunLTOPFull(cfg,sleep_time=30)\n",
    "        # single_example.runner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the first SNIC step \n",
    "#note that if you run this thing and the outputs already exist you will get an error in the task generation \n",
    "status1,status2 = runSNIC.generate_snic_outputs(cfg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step we run the kmeans algorithm which will automatically grab the snic outputs to do that process. This is not exposed to the user and assumes that you have specified the child and root directories where you want things to go in the params.py file. The following code block will check if the snic process is done and then when it determines that process has concluded it will execute the kmeans step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#similar to snic, if you run this and create the tasks in GEE you will hit an error if those things already exist \n",
    "km_status = kmeans_1.generate_snic_outputs(cfg)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step we just take the kmeans output and do a stratified random sample to get one point for each cluster id in the kmeans output image. Like the previous step, this one will also check to see if the output is done before executing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#similar to snic, if you run this and create the tasks in GEE you will hit an error if those things already exist \n",
    "km_pts_status = kmeans_2.generate_tasks(cfg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to create the abstract images. Previously to the Python implementation, these were created from a CSV which was generated in GEE and then pulled down to a local machine. The actual images were constructed in Numpy and then re-uploaded to GEE. This is a pretty inefficient process and therefore we are moving it to a GEE-assets generation type process. This is based on some code that Jack Kilbride wrote to replace the Numpy scheme and is still in testing as of 10/6/2022. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will throw an error in GEE if these already exist \n",
    "ab_imgs_status = ab_img.create_abstract_imgs(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we run landtrendr on the abstract image points, using the indices generated in the previous step as inputs. The scripts for the 04 step should be prepped to handle assets as inputs and will expect an imageCollection of abstract images as well as the points that were generated in the previous step that show where the abstract image pixels are located (centroids). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in the full workflow this happens in GCS. If we're just going to test it we don't really need to go to GCS because we just want to look at the outputs. \n",
    "#note that just for testing this has been changed so it will export csvs to a HARDCODED Google Drive folder called LTOP_TESTING. It will not send things to GCS. This\n",
    "#means that you need to manually inspect and download those data!!\n",
    "#update the outfile name so we can generate a test output\n",
    "cfg['outfile'] = cfg['outfile'][:-4] + '_param_testing_from_nb.csv'\n",
    "\n",
    "cfg['outfile']\n",
    "\n",
    "lt_pt_status = run_lt_pts.run_LT_abstract_imgs(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we incorporate the sections that were previously done in Python to accomplish the LT versions scoring. This likely needs to be amended still. Ideally, we wouldn't have to generate the giant csv and move that around for scoring. However, that is a fairly substantial lift to move all of that python code to GEE so for now it will stay as it is but this is a TODO for the future. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update the inputs and outputs in the params from the yml file to run this manually \n",
    "input_dir = \"/vol/v1/proj/LTOP_FTV_Py/param_selection_testing_inputs\"\n",
    "outfile = '/vol/v1/proj/LTOP_FTV_Py/param_selection_testing_outputs/LTOP_param_selected_testing_fixed_ties.csv'\n",
    "cfg['param_scoring_inputs'] = input_dir\n",
    "cfg['outfile'] = outfile\n",
    "\n",
    "param_scoring.generate_selected_params(cfg) \n",
    "\n",
    "# \tmain(input_dir,njobs,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the output of the gcs file checking function \n",
    "files = ['LTOP_cambodia_selected_params.csv','LTOP_cambodia_test_selected_params','something']\n",
    "test = ltop.check_multiple_gcs_files(files,'ltop_assets_storage')\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we run the last (05) step in the LTOP workflow. This step takes in the selected LT versions and it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt_vertices_status = make_bps.generate_LTOP_breakpoints(cfg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('ltop_py')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13 (default, Mar 29 2022, 02:18:16) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "757548dda17506bf7478dcf5c19d54dd277731f0c6e8d9deffb7323e66285ff1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
