{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running the LTOP workflow there is a circumstance where ties can occur in the paramater selection process. In these instances, version 0.1.0 is just selecting the first item in the df. However, for reproducability and to improve the param set pick, a more codified score/rank approach is required. This notebook is for working out the logic of that process before it is integrated into the existing workflow. This was developed in the ltop_py env on Islay. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import numpy as np \n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the intermediate param selection outputs - this path can be changed to a local version\n",
    "fn = r'/vol/v1/proj/LTOP_FTV_Py/param_selection_testing_outputs/intermediate_testing_output.csv'\n",
    "df = pd.read_csv(fn)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####set some user args#### \n",
    "#select a cluster id, not sure if this is what we want to do or if we want to iterate? \n",
    "select_cluster = 37\n",
    "clust_df = df.loc[df.cluster_id == select_cluster]\n",
    "clust_df.columns\n",
    "#select the param you want to plot \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_mean(df1,col_name): \n",
    "    '''\n",
    "    Calculate the mean of the combined rankVscore and rankAICcscore, considering the weighting factors, \n",
    "    for each possible value for a given param. Then take the max mean value. \n",
    "    '''\n",
    "    #this assumes you've already subset by cluster_id as is the case in the param selection code \n",
    "    #get the mean by possible param values \n",
    "    df1 = pd.DataFrame(df1.groupby([col_name])['combined'].mean()).reset_index()\n",
    "    # df1 = df.sort_values('combined')\n",
    "    # #get the max mean value for the given param \n",
    "    # df2 = df1.loc[df1['combined'] == df1['combined'].max()]\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ben.roberts/.conda/envs/ltop_py/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "/home/ben.roberts/.conda/envs/ltop_py/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/ben.roberts/.conda/envs/ltop_py/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/ben.roberts/.conda/envs/ltop_py/lib/python3.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5, 67)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#do the subsetting \n",
    "#first get the max mean value for each param - this will be a one line dataframe for the cluster id in question\n",
    "#do recoveryThreshold first\n",
    "#TODO do we want to calculate these means on the whole cluster_id? or just on the tied ones? \n",
    "rec_select = get_max_mean(clust_df,'recoveryThreshold')\n",
    "#next do spikeThreshold\n",
    "spike_select = get_max_mean(clust_df,'spikeThreshold')\n",
    "#then maxSegments\n",
    "max_select = get_max_mean(clust_df,'maxSegments')\n",
    "#then pvalThreshold \n",
    "pval_select = get_max_mean(clust_df,'pvalThreshold')\n",
    "\n",
    "clust_df['rec_rank'] = clust_df['recoveryThreshold'].map(dict(zip(rec_select.recoveryThreshold,rec_select.combined)))\n",
    "clust_df['spike_rank'] = clust_df['spikeThreshold'].map(dict(zip(spike_select.spikeThreshold,spike_select.combined)))\n",
    "clust_df['max_rank'] = clust_df['maxSegments'].map(dict(zip(max_select.maxSegments,max_select.combined)))\n",
    "clust_df['pval_rank'] = clust_df['pvalThreshold'].map(dict(zip(pval_select.pvalThreshold,pval_select.combined)))\n",
    "\n",
    "#then do the sequential subsetting, starting with the full dataframe - in the actual code this is a subset of the df for the cluster\n",
    "# #TODO the clust_df here is not actually correct, that will be the ties not the full df for the cluster_id\n",
    "clust_df.rec_rank.max()\n",
    "df1 = clust_df.loc[clust_df.rec_rank == clust_df.rec_rank.max()]\n",
    "df2 = df1.loc[df1.spike_rank == df1.spike_rank.max()]\n",
    "df3 = df2.loc[df2.max_rank == df2.max_rank.max()]\n",
    "df4 = df3.loc[df3.pval_rank == df3.pval_rank.max()]\n",
    "\n",
    "df4.shape\n",
    "# df2 = df1.loc[df1.spikeThreshold == spike_select.spikeThreshold.iloc[0]]\n",
    "# df3 = df2.loc[df2.maxSegments == max_select.maxSegments.iloc[0]]\n",
    "# df4 = df3.loc[df3.pvalThreshold == pval_select.pvalThreshold.iloc[0]]\n",
    "\n",
    "#this will be the output, which ideally has only one row left? \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('ltop_py')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "757548dda17506bf7478dcf5c19d54dd277731f0c6e8d9deffb7323e66285ff1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
